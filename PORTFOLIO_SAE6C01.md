# üìä Analyse de Donn√©es Massives - Yelp Dataset

**Projet Acad√©mique (BUT Informatique S6)** | *Data Science, NLP & Machine Learning*

---

## üí° Pr√©sentation du Projet

Ce projet vise √† explorer et analyser le **Yelp Academic Dataset**, un ensemble de donn√©es volumineux contenant des millions d'avis, de commerces et d'utilisateurs. L'objectif principal est d'extraire des insights pertinents et de d√©velopper des mod√®les pr√©dictifs pour comprendre les interactions entre clients et entreprises.

Le projet met en ≈ìuvre un pipeline de donn√©es complet, allant du nettoyage de donn√©es brutes (JSON) √† l'entra√Ænement de mod√®les de Machine Learning et de Deep Learning (NLP), en passant par une analyse exploratoire approfondie.

## üõ†Ô∏è Stack Technique

*   **Langage & Environnement**: Python 3.12+, Jupyter Notebooks
*   **Data Engineering**: `Pandas` (Manipulation), `Numpy`, `Parquet` (Stockage optimis√©)
*   **NLP (Traitement du Langage Naturel)**:
    *   `NLTK`, `Spacy` (Nettoyage, Tokenization)
    *   `Scikit-learn` (TF-IDF)
    *   `Gensim` (Word2Vec - Word Embeddings)
    *   `Transformers` (HuggingFace - LLMs comme BERT)
*   **Machine Learning**: `Scikit-learn` (Classification, Clustering), `PyTorch`
*   **Visualisation**: `Matplotlib`, `Seaborn`, `Plotly` (Graphiques interactifs)
*   **Version Control & Gestion**: Git/GitHub, Linear (Agile), VS Code

## üöÄ Fonctionnalit√©s Cl√©s & R√©alisations

### 1. Pipeline de Donn√©es & Optimisation
*   Traitement de datasets volumineux (~6 Go de JSON brut) avec conversion vers le format **Parquet** pour optimiser les temps de chargement et l'empreinte m√©moire.
*   Gestion efficace des types de donn√©es et nettoyage robuste (gestion des valeurs manquantes, d√©tection d'anomalies).

### 2. Analyse Exploratoire de Donn√©es (EDA)
*   Analyses statistiques de la distribution des notes, des longueurs d'avis et de l'activit√© des utilisateurs.
*   Visualisations g√©ospatiales de la r√©partition des commerces.
*   √âtude des corr√©lations entre les attributs des commerces et leur popularit√©.

### 3. NLP & Feature Engineering
*   **Pr√©traitement Textuel**: Pipeline de nettoyage incluant la suppression des stopwords, la lemmatisation et la normalisation.
*   **Repr√©sentation Vectorielle**:
    *   Impl√©mentation de **TF-IDF** (avec optimisation des **N-grammes**) pour identifier les termes significatifs.
    *   Entra√Ænement de mod√®les **Word2Vec** pour capturer le contexte s√©matique des mots.
    *   Utilisation d'**Embeddings** de documents et de LLMs.

### 4. Mod√©lisation & Inf√©rence (Strat√©gie √âvaluation)
*   **Approche Hybride**: Comparaison syst√©matique entre :
    *   **ML Classique**: R√©gression Logistique, SVM, Random Forest (sur N-grams & TF-IDF).
    *   **Deep Learning**: Architectures neuronales avanc√©es (PyTorch) et Fine-tuning de LLMs (BERT).
*   **Pipeline d'Inf√©rence**: Syst√®me robuste con√ßu pour **pr√©dire sur de nouvelles donn√©es de test** (capacit√© de g√©n√©ralisation v√©rifi√©e).
*   **Comparaison Mod√®le Optimal**: S√©lection du meilleur mod√®le (Classique vs Deep) bas√© sur les m√©triques de performance sur donn√©es invisibles.
*   **A venir**:
    *   Clustering K-Means et visualisation t-SNE.
    *   Syst√®me de recommandation.

### 5. DevOps & Automation
*   **Int√©gration Continue (CI/CD)**: Configuration compl√®te de l'environnement avec `venv` et gestion des d√©pendances.
*   **Linear ‚Üî GitHub**: Mise en place d'une synchronisation bidirectionnelle. Les commits et PRs mettent automatiquement √† jour le statut des tickets Linear.
*   **Documentation Automatis√©e**: G√©n√©ration de documentation technique et contextuelle pour les assistants IA.

## üë®‚Äçüíª M√©thodologie

*   **Agile**: Organisation en sprints avec suivi des t√¢ches sur Linear.
*   **Code Quality**: Respect des standards Python (PEP8), documentation des fonctions, et architecture modulaire (`src/` pour le code r√©utilisable).
*   **Collaboration**: Workflow Git strict avec Pull Requests et Code Reviews.

## üìÇ Structure du R√©pertoire

```bash
‚îú‚îÄ‚îÄ data/          # Donn√©es brutes et nettoy√©es (Parquet)
‚îú‚îÄ‚îÄ notebooks/     # Analyses exp√©rimentales et visualisations (Jupyter)
‚îú‚îÄ‚îÄ src/           # Modules Python (ETL, NLP, Viz)
‚îú‚îÄ‚îÄ outputs/       # Rapports g√©n√©r√©s et graphiques
‚îî‚îÄ‚îÄ docs/          # Documentation technique et guides
```

---
*Ce projet a √©t√© r√©alis√© dans le cadre du semestre 6 du BUT Informatique, en √©quipe de 5 √©tudiants.*
